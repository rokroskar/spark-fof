{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a simple synthetic dataset to test hierarchical merge in FOF algorithm\n",
    "\n",
    "#### the idea is this: \n",
    "\n",
    "* after the local FOF stage, each partition reports the particles it holds in the overlap region\n",
    "* do a reduceByKey or treeAggregate of some sort to collect the groups belonging to the same particles\n",
    "* produce a mapping of $G -> G_1$ and distribute to all hosts in form of broadcast lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rok/miniconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(sys.getrecursionlimit()*10)\n",
    "\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spark_fof\n",
    "reload(spark_fof)\n",
    "from spark_fof import Particle, groupID, get_bin, set_local_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rectangle(rec, ax=None):\n",
    "    if ax is None: \n",
    "        ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    if isinstance(rec, (list, tuple)):\n",
    "        for r in rec: \n",
    "            plot_rectangle(r,ax)\n",
    "    \n",
    "    else:\n",
    "        size = (rec.maxes-rec.mins)\n",
    "        ax.add_patch(patches.Rectangle(rec.mins, size[0], size[1], fill=False, zorder=-1))\n",
    "    \n",
    "    plt.xlim(-1.1,1.1); plt.ylim(-1.1,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append(Particle(-.35,-.35,0,groupID(1,1)))\n",
    "data.append(Particle(-.27,-.27,1,groupID(1,1)))\n",
    "data.append(Particle(-.23,-.23,2,groupID(1,1)))\n",
    "data.append(Particle(-.19,-.19,3,groupID(1,1)))\n",
    "data.append(Particle(-.01,-.01,4,groupID(1,1)))\n",
    "data.append(Particle(0.01,0.01,5,groupID(1,1)))\n",
    "data.append(Particle(0.23,0.23,6,groupID(1,1)))\n",
    "data.append(Particle(0.29,0.29,7,groupID(1,1)))\n",
    "data.append(Particle(0.49,0.49,8,groupID(1,1)))\n",
    "data.append(Particle(0.51,0.51,9,groupID(1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_array = np.zeros(len(data), dtype = spark_fof.pdt)\n",
    "for i,p in enumerate(data): \n",
    "    data_array[i]['x'] = p.x\n",
    "    data_array[i]['y'] = p.y\n",
    "    data_array[i]['pid'] = p.pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['SPARK_DRIVER_MEMORY']= '4G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x114c0dcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.python.profile', 'true')\n",
    "conf.set('spark.executor.memory', '5G')\n",
    "conf.set('spark.driver.memory', '4G')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local[4]', conf=conf, batchSize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.addPyFile('spark_fof.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "tau = 0.05\n",
    "mins = [-1,-1]\n",
    "maxes= [1,1]\n",
    "domain_containers = spark_fof.setup_domain(N,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAANhCAYAAABwxYOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c98a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(subplot_kw={'aspect':'equal'}, figsize=(15,15))\n",
    "#plot_rectangle(domain_containers[0].bufferRectangle, ax=ax)\n",
    "for p in data: \n",
    "    plot_rectangle(domain_containers[get_bin(p.x, p.y, 2**N, mins,maxes)], ax=ax)\n",
    "    plot_rectangle(domain_containers[get_bin(p.x, p.y, 2**N, mins,maxes)].bufferRectangle, ax=ax)\n",
    "    ax.plot(p.x, p.y, 'o')\n",
    "for r in domain_containers: \n",
    "    plot_rectangle(r.parent, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the base RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_rdd = sc.parallelize(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.3499999940395355, -0.3499999940395355, 0, 0),\n",
       " (-0.27000001072883606, -0.27000001072883606, 1, 0),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 0),\n",
       " (-0.1899999976158142, -0.1899999976158142, 3, 0),\n",
       " (-0.009999999776482582, -0.009999999776482582, 4, 0),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 0),\n",
       " (0.23000000417232513, 0.23000000417232513, 6, 0),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 0),\n",
       " (0.49000000953674316, 0.49000000953674316, 8, 0),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition particles into domains and set the partition part of local group ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# partitioning duplicates the particles that are located in the boundary regions\n",
    "part_rdd = (p_rdd.mapPartitions(lambda particles: spark_fof.partition_particles(particles, domain_containers, tau))\n",
    "                 .partitionBy(len(domain_containers))\n",
    "                 .values()\n",
    "                 .mapPartitionsWithIndex(set_local_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the partitioned RDD -- some of the particles will be duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parts = part_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (-0.3499999940395355, -0.3499999940395355, 0, 77309411328)\n",
      "1 (-0.27000001072883606, -0.27000001072883606, 1, 77309411328)\n",
      "2 (-0.23000000417232513, -0.23000000417232513, 2, 77309411328)\n",
      "3 (-0.23000000417232513, -0.23000000417232513, 2, 81604378624)\n",
      "4 (-0.23000000417232513, -0.23000000417232513, 2, 111669149696)\n",
      "5 (-0.23000000417232513, -0.23000000417232513, 2, 115964116992)\n",
      "6 (-0.1899999976158142, -0.1899999976158142, 3, 115964116992)\n",
      "7 (-0.009999999776482582, -0.009999999776482582, 4, 115964116992)\n",
      "8 (0.009999999776482582, 0.009999999776482582, 5, 115964116992)\n",
      "9 (0.009999999776482582, 0.009999999776482582, 5, 120259084288)\n",
      "10 (0.009999999776482582, 0.009999999776482582, 5, 150323855360)\n",
      "11 (0.009999999776482582, 0.009999999776482582, 5, 154618822656)\n",
      "12 (0.23000000417232513, 0.23000000417232513, 6, 154618822656)\n",
      "13 (0.28999999165534973, 0.28999999165534973, 7, 154618822656)\n",
      "14 (0.28999999165534973, 0.28999999165534973, 7, 158913789952)\n",
      "15 (0.28999999165534973, 0.28999999165534973, 7, 188978561024)\n",
      "16 (0.28999999165534973, 0.28999999165534973, 7, 193273528320)\n",
      "17 (0.49000000953674316, 0.49000000953674316, 8, 193273528320)\n",
      "18 (0.5099999904632568, 0.5099999904632568, 9, 193273528320)\n",
      "19 (0.5099999904632568, 0.5099999904632568, 9, 197568495616)\n",
      "20 (0.5099999904632568, 0.5099999904632568, 9, 227633266688)\n",
      "21 (0.5099999904632568, 0.5099999904632568, 9, 231928233984)\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(parts): \n",
    "    print i, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Merging stage\n",
    "\n",
    "#### Ugly hack to create a 'fake' data set to look like what we would get out of a first FOF pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_partitions = []\n",
    "for p in parts: \n",
    "    data_partitions.append(spark_fof.decode_gid(p['gid'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fof_rdd = sc.parallelize(zip(data_partitions, parts)).partitionBy(len(domain_containers)).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.3499999940395355, -0.3499999940395355, 0, 77309411328),\n",
       " (-0.27000001072883606, -0.27000001072883606, 1, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 81604378624),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 111669149696),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 115964116992),\n",
       " (-0.1899999976158142, -0.1899999976158142, 3, 115964116992),\n",
       " (-0.009999999776482582, -0.009999999776482582, 4, 115964116992),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 115964116992),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 120259084288),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 150323855360),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 154618822656),\n",
       " (0.23000000417232513, 0.23000000417232513, 6, 154618822656),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 154618822656),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 158913789952),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 188978561024),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 193273528320),\n",
       " (0.49000000953674316, 0.49000000953674316, 8, 193273528320),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 193273528320),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 197568495616),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 227633266688),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 231928233984)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fof_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mappings_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fof_analyzer = spark_fof.FOFAnalyzer(sc, N, tau, fof_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_rdd = fof_analyzer.merge_groups(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.3499999940395355, -0.3499999940395355, 0, 77309411328),\n",
       " (-0.27000001072883606, -0.27000001072883606, 1, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       " (-0.1899999976158142, -0.1899999976158142, 3, 77309411328),\n",
       " (-0.009999999776482582, -0.009999999776482582, 4, 77309411328),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       " (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       " (0.23000000417232513, 0.23000000417232513, 6, 77309411328),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       " (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       " (0.49000000953674316, 0.49000000953674316, 8, 77309411328),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       " (0.5099999904632568, 0.5099999904632568, 9, 77309411328)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Profile of RDD<id=26>\n",
      "============================================================\n",
      "         2077 function calls (2013 primitive calls) in 0.007 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       44    0.001    0.000    0.002    0.000 kdtree.py:119(min_distance_point)\n",
      "       64    0.001    0.000    0.005    0.000 serializers.py:259(dump_stream)\n",
      "       13    0.000    0.000    0.000    0.000 {cPickle.loads}\n",
      "       44    0.000    0.000    0.001    0.000 kdtree.py:15(minkowski_distance_p)\n",
      "       68    0.000    0.000    0.005    0.000 spark_fof.py:258(get_buffer_particles)\n",
      "       77    0.000    0.000    0.002    0.000 serializers.py:136(load_stream)\n",
      "       77    0.000    0.000    0.001    0.000 serializers.py:542(read_int)\n",
      "       44    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "       77    0.000    0.000    0.001    0.000 serializers.py:155(_read_with_length)\n",
      "       64    0.000    0.000    0.007    0.000 worker.py:104(process)\n",
      "       22    0.000    0.000    0.002    0.000 spark_fof.py:386(in_buffer_zone)\n",
      "   128/64    0.000    0.000    0.000    0.000 rdd.py:2345(pipeline_func)\n",
      "       90    0.000    0.000    0.000    0.000 {method 'read' of 'file' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.dumps}\n",
      "       44    0.000    0.000    0.001    0.000 kdtree.py:49(minkowski_distance)\n",
      "       44    0.000    0.000    0.001    0.000 fromnumeric.py:1743(sum)\n",
      "      176    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}\n",
      "      176    0.000    0.000    0.000    0.000 numeric.py:414(asarray)\n",
      "       77    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "      128    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "       64    0.000    0.000    0.000    0.000 spark_fof.py:62(<lambda>)\n",
      "       44    0.000    0.000    0.000    0.000 _methods.py:31(_sum)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "       64    0.000    0.000    0.000    0.000 {range}\n",
      "       44    0.000    0.000    0.000    0.000 {isinstance}\n",
      "       13    0.000    0.000    0.000    0.000 serializers.py:421(loads)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "       64    0.000    0.000    0.000    0.000 {iter}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "       22    0.000    0.000    0.000    0.000 rdd.py:1540(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 spark_fof.py:271(pid_gid)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:414(dumps)\n",
      "       21    0.000    0.000    0.000    0.000 {len}\n",
      "        4    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "\n",
      "\n",
      "============================================================\n",
      "Profile of RDD<id=27>\n",
      "============================================================\n",
      "         4845 function calls (4653 primitive calls) in 0.014 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       64    0.001    0.000    0.002    0.000 shuffle.py:69(_get_local_dirs)\n",
      "       64    0.001    0.000    0.004    0.000 shuffle.py:196(__init__)\n",
      "       64    0.001    0.000    0.006    0.000 shuffle.py:229(mergeValues)\n",
      "       16    0.001    0.000    0.001    0.000 {cPickle.dumps}\n",
      "       64    0.001    0.000    0.001    0.000 posixpath.py:61(join)\n",
      "       13    0.000    0.000    0.000    0.000 {cPickle.loads}\n",
      "       64    0.000    0.000    0.002    0.000 shuffle.py:37(get_used_memory)\n",
      "       64    0.000    0.000    0.011    0.000 rdd.py:1774(combineLocally)\n",
      "       64    0.000    0.000    0.000    0.000 {psutil._psutil_osx.proc_memory_info}\n",
      "       64    0.000    0.000    0.001    0.000 _psosx.py:267(memory_info)\n",
      "       96    0.000    0.000    0.001    0.000 rdd.py:1697(add_shuffle_key)\n",
      "        4    0.000    0.000    0.000    0.000 {open}\n",
      "   256/64    0.000    0.000    0.011    0.000 rdd.py:2345(pipeline_func)\n",
      "       64    0.000    0.000    0.001    0.000 shuffle.py:134(_compressed_serializer)\n",
      "       64    0.000    0.000    0.000    0.000 <string>:8(__new__)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "       77    0.000    0.000    0.002    0.000 serializers.py:136(load_stream)\n",
      "       77    0.000    0.000    0.000    0.000 serializers.py:542(read_int)\n",
      "       64    0.000    0.000    0.014    0.000 worker.py:104(process)\n",
      "      128    0.000    0.000    0.011    0.000 rdd.py:316(func)\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:91(get)\n",
      "       64    0.000    0.000    0.000    0.000 shuffle.py:337(items)\n",
      "       77    0.000    0.000    0.001    0.000 serializers.py:155(_read_with_length)\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.load}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:481(__init__)\n",
      "      128    0.000    0.000    0.000    0.000 serializers.py:127(__init__)\n",
      "       64    0.000    0.000    0.002    0.000 __init__.py:936(memory_info)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:255(__init__)\n",
      "       22    0.000    0.000    0.000    0.000 spark_fof.py:271(pid_gid)\n",
      "       16    0.000    0.000    0.000    0.000 copy.py:145(deepcopy)\n",
      "       90    0.000    0.000    0.000    0.000 {method 'read' of 'file' objects}\n",
      "       64    0.000    0.000    0.002    0.000 serializers.py:132(dump_stream)\n",
      "       32    0.000    0.000    0.000    0.000 serializers.py:143(_write_with_length)\n",
      "       64    0.000    0.000    0.001    0.000 _psosx.py:196(wrapper)\n",
      "      128    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "        4    0.000    0.000    0.001    0.000 broadcast.py:82(load)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "       16    0.000    0.000    0.000    0.000 copy.py:267(_keep_alive)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       22    0.000    0.000    0.001    0.000 spark_fof.py:79(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x100186920}\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:103(__contains__)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 rdd.py:366(func)\n",
      "       80    0.000    0.000    0.000    0.000 {isinstance}\n",
      "       64    0.000    0.000    0.000    0.000 shuffle.py:118(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "       64    0.000    0.000    0.000    0.000 {min}\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:35(__getitem__)\n",
      "       48    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "      128    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "       86    0.000    0.000    0.000    0.000 {hasattr}\n",
      "       77    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:190(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       22    0.000    0.000    0.001    0.000 broadcast.py:92(value)\n",
      "       16    0.000    0.000    0.000    0.000 rdd.py:61(portable_hash)\n",
      "      192    0.000    0.000    0.000    0.000 {id}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "       16    0.000    0.000    0.000    0.000 rdd.py:1800(createZero)\n",
      "      128    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       16    0.000    0.000    0.001    0.000 serializers.py:414(dumps)\n",
      "       16    0.000    0.000    0.000    0.000 rdd.py:1804(<lambda>)\n",
      "      141    0.000    0.000    0.000    0.000 {len}\n",
      "       16    0.000    0.000    0.000    0.000 serializers.py:538(pack_long)\n",
      "       64    0.000    0.000    0.000    0.000 {iter}\n",
      "       13    0.000    0.000    0.001    0.000 serializers.py:421(loads)\n",
      "       16    0.000    0.000    0.000    0.000 copy.py:226(_deepcopy_list)\n",
      "       16    0.000    0.000    0.000    0.000 spark_fof.py:80(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       22    0.000    0.000    0.000    0.000 rdd.py:1540(<lambda>)\n",
      "       32    0.000    0.000    0.000    0.000 serializers.py:335(dumps)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {gc.enable}\n",
      "       16    0.000    0.000    0.000    0.000 {hash}\n",
      "        4    0.000    0.000    0.000    0.000 {gc.disable}\n",
      "\n",
      "\n",
      "============================================================\n",
      "Profile of RDD<id=31>\n",
      "============================================================\n",
      "         3904 function calls (3840 primitive calls) in 0.011 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       64    0.001    0.000    0.002    0.000 shuffle.py:69(_get_local_dirs)\n",
      "       64    0.001    0.000    0.004    0.000 shuffle.py:196(__init__)\n",
      "       64    0.001    0.000    0.001    0.000 serializers.py:259(dump_stream)\n",
      "       64    0.001    0.000    0.004    0.000 shuffle.py:263(mergeCombiners)\n",
      "       64    0.000    0.000    0.001    0.000 posixpath.py:61(join)\n",
      "       64    0.000    0.000    0.000    0.000 {psutil._psutil_osx.proc_memory_info}\n",
      "       80    0.000    0.000    0.001    0.000 serializers.py:136(load_stream)\n",
      "       64    0.000    0.000    0.001    0.000 _psosx.py:267(memory_info)\n",
      "       64    0.000    0.000    0.002    0.000 shuffle.py:37(get_used_memory)\n",
      "       64    0.000    0.000    0.008    0.000 rdd.py:1782(_mergeCombiners)\n",
      "        8    0.000    0.000    0.000    0.000 {cPickle.dumps}\n",
      "       64    0.000    0.000    0.001    0.000 shuffle.py:134(_compressed_serializer)\n",
      "       64    0.000    0.000    0.011    0.000 worker.py:104(process)\n",
      "       64    0.000    0.000    0.000    0.000 <string>:8(__new__)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "       64    0.000    0.000    0.002    0.000 __init__.py:936(memory_info)\n",
      "       64    0.000    0.000    0.000    0.000 shuffle.py:337(items)\n",
      "       80    0.000    0.000    0.000    0.000 serializers.py:542(read_int)\n",
      "   128/64    0.000    0.000    0.009    0.000 rdd.py:2345(pipeline_func)\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:91(get)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:481(__init__)\n",
      "       80    0.000    0.000    0.001    0.000 serializers.py:155(_read_with_length)\n",
      "       16    0.000    0.000    0.000    0.000 {cPickle.loads}\n",
      "       64    0.000    0.000    0.009    0.000 rdd.py:316(func)\n",
      "      128    0.000    0.000    0.000    0.000 serializers.py:127(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:255(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 rdd.py:303(func)\n",
      "       96    0.000    0.000    0.000    0.000 {method 'read' of 'file' objects}\n",
      "       64    0.000    0.000    0.001    0.000 _psosx.py:196(wrapper)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:103(__contains__)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x100186920}\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:190(__init__)\n",
      "      128    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "       64    0.000    0.000    0.000    0.000 shuffle.py:118(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 UserDict.py:35(__getitem__)\n",
      "       80    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "       64    0.000    0.000    0.000    0.000 {hasattr}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "      128    0.000    0.000    0.000    0.000 {id}\n",
      "       64    0.000    0.000    0.000    0.000 {isinstance}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "       12    0.000    0.000    0.000    0.000 {sorted}\n",
      "       96    0.000    0.000    0.000    0.000 {len}\n",
      "      128    0.000    0.000    0.000    0.000 {iter}\n",
      "        8    0.000    0.000    0.000    0.000 serializers.py:414(dumps)\n",
      "       16    0.000    0.000    0.000    0.000 serializers.py:421(loads)\n",
      "       12    0.000    0.000    0.000    0.000 spark_fof.py:80(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 spark_fof.py:82(<lambda>)\n",
      "       16    0.000    0.000    0.000    0.000 shuffle.py:257(_object_size)\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:1540(<lambda>)\n",
      "\n",
      "\n",
      "============================================================\n",
      "Profile of RDD<id=32>\n",
      "============================================================\n",
      "         1891 function calls in 0.008 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       64    0.001    0.000    0.004    0.000 spark_fof.py:285(remap_gid_partition)\n",
      "       18    0.001    0.000    0.001    0.000 {cPickle.dumps}\n",
      "        4    0.001    0.000    0.001    0.000 {open}\n",
      "       64    0.001    0.000    0.002    0.000 serializers.py:259(dump_stream)\n",
      "       64    0.001    0.000    0.001    0.000 arraysetops.py:96(unique)\n",
      "       64    0.000    0.000    0.002    0.000 {numpy.core.multiarray.fromiter}\n",
      "       13    0.000    0.000    0.000    0.000 {cPickle.loads}\n",
      "       64    0.000    0.000    0.008    0.000 worker.py:104(process)\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.load}\n",
      "       77    0.000    0.000    0.001    0.000 serializers.py:136(load_stream)\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "       64    0.000    0.000    0.005    0.000 spark_fof.py:158(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "       77    0.000    0.000    0.000    0.000 serializers.py:542(read_int)\n",
      "       77    0.000    0.000    0.001    0.000 serializers.py:155(_read_with_length)\n",
      "       64    0.000    0.000    0.000    0.000 numeric.py:484(asanyarray)\n",
      "       64    0.000    0.000    0.001    0.000 broadcast.py:92(value)\n",
      "       64    0.000    0.000    0.005    0.000 rdd.py:2345(pipeline_func)\n",
      "       90    0.000    0.000    0.000    0.000 {method 'read' of 'file' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}\n",
      "       64    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "        4    0.000    0.000    0.001    0.000 broadcast.py:82(load)\n",
      "       64    0.000    0.000    0.005    0.000 rdd.py:316(func)\n",
      "       64    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "       18    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "       64    0.000    0.000    0.000    0.000 {hasattr}\n",
      "       64    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "       77    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "       18    0.000    0.000    0.001    0.000 serializers.py:414(dumps)\n",
      "       18    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "       13    0.000    0.000    0.000    0.000 serializers.py:421(loads)\n",
      "       13    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}\n",
      "       64    0.000    0.000    0.000    0.000 {iter}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       49    0.000    0.000    0.000    0.000 {len}\n",
      "       22    0.000    0.000    0.000    0.000 rdd.py:1540(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 {gc.enable}\n",
      "        4    0.000    0.000    0.000    0.000 {gc.disable}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.show_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_arr = np.array(fof_analyzer.particle_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = np.unique(p_arr['gid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in groups:\n",
    "    inds = np.where(p_arr['gid'] == g)\n",
    "    if g in m.keys():\n",
    "        p_arr['gid'][inds] = m[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(-0.3499999940395355, -0.3499999940395355, 0, 77309411328),\n",
       "       (-0.27000001072883606, -0.27000001072883606, 1, 77309411328),\n",
       "       (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       "       (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       "       (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       "       (-0.23000000417232513, -0.23000000417232513, 2, 77309411328),\n",
       "       (-0.1899999976158142, -0.1899999976158142, 3, 77309411328),\n",
       "       (-0.009999999776482582, -0.009999999776482582, 4, 77309411328),\n",
       "       (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       "       (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       "       (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       "       (0.009999999776482582, 0.009999999776482582, 5, 77309411328),\n",
       "       (0.23000000417232513, 0.23000000417232513, 6, 77309411328),\n",
       "       (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       "       (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       "       (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       "       (0.28999999165534973, 0.28999999165534973, 7, 77309411328),\n",
       "       (0.49000000953674316, 0.49000000953674316, 8, 77309411328),\n",
       "       (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       "       (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       "       (0.5099999904632568, 0.5099999904632568, 9, 77309411328),\n",
       "       (0.5099999904632568, 0.5099999904632568, 9, 77309411328)], \n",
       "      dtype=[('x', '<f4'), ('y', '<f4'), ('pid', '<i8'), ('gid', '<i8')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remap_gid_partition(particles, gid_map):\n",
    "    p_arr = np.fromiter(particles, spark_fof.pdt)\n",
    "    groups = np.unique(p_arr['gid'])\n",
    "    for g in groups:\n",
    "        inds = np.where(p_arr['gid'] == g)\n",
    "        if g in gid_map.keys():\n",
    "            p_arr['gid'][inds] = gid_map[g]\n",
    "    return p_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = fof_analyzer.particle_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.3499999940395355, -0.3499999940395355, 0, 77309411328),\n",
       " (-0.27000001072883606, -0.27000001072883606, 0, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 0, 77309411328),\n",
       " (-0.23000000417232513, -0.23000000417232513, 0, 81604378624),\n",
       " (-0.23000000417232513, -0.23000000417232513, 0, 111669149696),\n",
       " (-0.23000000417232513, -0.23000000417232513, 0, 115964116992),\n",
       " (-0.1899999976158142, -0.1899999976158142, 0, 115964116992),\n",
       " (-0.009999999776482582, -0.009999999776482582, 0, 115964116992),\n",
       " (0.009999999776482582, 0.009999999776482582, 0, 115964116992),\n",
       " (0.009999999776482582, 0.009999999776482582, 0, 120259084288),\n",
       " (0.009999999776482582, 0.009999999776482582, 0, 150323855360),\n",
       " (0.009999999776482582, 0.009999999776482582, 0, 154618822656),\n",
       " (0.23000000417232513, 0.23000000417232513, 0, 154618822656),\n",
       " (0.28999999165534973, 0.28999999165534973, 0, 154618822656),\n",
       " (0.28999999165534973, 0.28999999165534973, 0, 158913789952),\n",
       " (0.28999999165534973, 0.28999999165534973, 0, 188978561024),\n",
       " (0.28999999165534973, 0.28999999165534973, 0, 193273528320),\n",
       " (0.49000000953674316, 0.49000000953674316, 0, 193273528320),\n",
       " (0.5099999904632568, 0.5099999904632568, 0, 193273528320),\n",
       " (0.5099999904632568, 0.5099999904632568, 0, 197568495616),\n",
       " (0.5099999904632568, 0.5099999904632568, 0, 227633266688),\n",
       " (0.5099999904632568, 0.5099999904632568, 0, 231928233984)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fof_analyzer.particle_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## try get_bin with cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pyximport\n",
    "# pyximport.install(setup_args={\"include_dirs\":np.get_include()},\n",
    "#                   reload_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = np.random.rand(1000000)\n",
    "ys = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cython on workers\n",
    "\n",
    "looks like some helpful info here: https://www.4info.com/Blog/October-2014/Enhancing-Spark-with-IPython-Notebook-and-Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.addPyFile('spark_fof_c.pyx')\n",
    "sc.addPyFile('spark_util.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, <pyximport.pyximport.PyxImporter at 0x1187f4a50>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyximport\n",
    "pyximport.install(setup_args={\"include_dirs\":np.get_include()})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spark_util import spark_cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_particle_bin(p):\n",
    "    from spark_util import spark_cython\n",
    "    return spark_cython('spark_fof_c', 'get_bin_cython')(p.x,p.y,100,-1,-1,1,1)\n",
    "\n",
    "def get_particle_bin_numpy(p):\n",
    "    from spark_util import spark_cython\n",
    "    return spark_cython('spark_fof_c', 'get_bin_cython')(p['x'],p['y'],100,-1,-1,1,1)\n",
    "\n",
    "def get_particle_bin_partition(particles, n):\n",
    "    xs = np.zeros(n)\n",
    "    ys = np.zeros(n)\n",
    "    bins = np.zeros(n, dtype=np.int32)\n",
    "    \n",
    "    for i, p in enumerate(particles): \n",
    "        xs[i]=p.x\n",
    "        xs[i]=p.y\n",
    "    \n",
    "    spark_cython('spark_fof_c', 'get_particle_bins_cython')(xs,ys,bins)\n",
    "    \n",
    "    for bin in bins: yield bin\n",
    "\n",
    "def get_particle_bin_partition_numpy(particles): \n",
    "    p_arr = np.fromiter(particles, pdt)\n",
    "    bins = np.zeros(len(p_arr), dtype=np.int)\n",
    "    spark_cython('spark_fof_c', 'get_particle_bins_cython')(p_arr['x'], p_arr['y'], bins)\n",
    "    return bins\n",
    "\n",
    "def get_particle_bin_python(p):\n",
    "    return get_bin(p['x'],p['y'],100,[-1,-1],[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spark_fof import Particle, groupID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_arr = []\n",
    "\n",
    "for i, (x,y) in enumerate(zip(np.random.rand(1000000), np.random.rand(1000000))):\n",
    "    p_arr.append(Particle(x,y,i,groupID(0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdt = np.dtype([('x','f8'), ('y','f8')], )\n",
    "\n",
    "p_np_arr = np.zeros(1000000,dtype=pdt)\n",
    "\n",
    "for i in range(len(p_np_arr)):\n",
    "    p_np_arr[i] = np.random.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_arr_rdd = sc.parallelize(p_arr).cache()\n",
    "p_np_arr_rdd = sc.parallelize(p_np_arr).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_arr_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_np_arr_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.1 ms, sys: 1.85 ms, total: 7.95 ms\n",
      "Wall time: 2.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time p_arr_rdd.map(get_particle_bin).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Profile of RDD<id=29>\n",
      "============================================================\n",
      "         5009057 function calls (5009049 primitive calls) in 10.122 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      977    6.595    0.007    6.595    0.007 {cPickle.loads}\n",
      "  1000000    1.913    0.000    2.603    0.000 <ipython-input-34-70e5b75fae3f>:1(get_particle_bin)\n",
      "  1000004    0.722    0.000    9.981    0.000 rdd.py:1004(<genexpr>)\n",
      "  1000000    0.285    0.000    0.486    0.000 spark_util.py:4(wrapped)\n",
      "  1000000    0.204    0.000    0.204    0.000 spark_util.py:3(spark_cython)\n",
      "  1000000    0.201    0.000    0.201    0.000 {spark_fof_c.get_bin_cython}\n",
      "        8    0.140    0.018   10.121    1.265 {sum}\n",
      "     1958    0.042    0.000    0.042    0.000 {method 'read' of 'file' objects}\n",
      "      981    0.007    0.000    6.652    0.007 serializers.py:155(_read_with_length)\n",
      "      981    0.004    0.000    6.656    0.007 serializers.py:136(load_stream)\n",
      "      981    0.004    0.000    0.008    0.000 serializers.py:542(read_int)\n",
      "      977    0.002    0.000    6.598    0.007 serializers.py:421(loads)\n",
      "      981    0.001    0.000    0.001    0.000 {_struct.unpack}\n",
      "      993    0.000    0.000    0.000    0.000 {len}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:259(dump_stream)\n",
      "        4    0.000    0.000    0.000    0.000 pyximport.py:471(install)\n",
      "        4    0.000    0.000    0.000    0.000 posixpath.py:251(expanduser)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:21(get_include)\n",
      "     12/4    0.000    0.000   10.121    2.530 rdd.py:2345(pipeline_func)\n",
      "        4    0.000    0.000    0.000    0.000 posixpath.py:120(dirname)\n",
      "        4    0.000    0.000   10.122    2.530 worker.py:104(process)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "        4    0.000    0.000    0.000    0.000 {spark_fof_c.get_particle_bins_cython}\n",
      "        8    0.000    0.000    0.000    0.000 posixpath.py:61(join)\n",
      "       28    0.000    0.000    0.000    0.000 {isinstance}\n",
      "        4    0.000    0.000    0.000    0.000 pyximport.py:458(_have_importers)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.dumps}\n",
      "        4    0.000    0.000   10.121    2.530 rdd.py:1004(<lambda>)\n",
      "       12    0.000    0.000   10.121    0.843 rdd.py:316(func)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "        8    0.000    0.000    0.000    0.000 rdd.py:861(func)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:414(dumps)\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:995(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "        4    0.000    0.000    0.000    0.000 {__import__}\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "        4    0.000    0.000    0.000    0.000 UserDict.py:35(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 UserDict.py:103(__contains__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {operator.add}\n",
      "        4    0.000    0.000    0.000    0.000 {getattr}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {iter}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.show_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 364 ms, sys: 10.9 ms, total: 375 ms\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%time bins = p_np_arr_rdd.mapPartitions(get_particle_bin_partition_numpy).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Profile of RDD<id=37>\n",
      "============================================================\n",
      "         1008961 function calls (1008953 primitive calls) in 0.500 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        4    0.135    0.034    0.135    0.034 {spark_fof_c.get_particle_bins_cython}\n",
      "  1000004    0.127    0.000    0.127    0.000 rdd.py:1004(<genexpr>)\n",
      "        4    0.123    0.031    0.153    0.038 {numpy.core.multiarray.fromiter}\n",
      "        8    0.082    0.010    0.209    0.026 {sum}\n",
      "      977    0.016    0.000    0.016    0.000 {cPickle.loads}\n",
      "     1958    0.007    0.000    0.007    0.000 {method 'read' of 'file' objects}\n",
      "      981    0.002    0.000    0.028    0.000 serializers.py:155(_read_with_length)\n",
      "      981    0.001    0.000    0.030    0.000 serializers.py:136(load_stream)\n",
      "       16    0.001    0.000    0.499    0.031 rdd.py:316(func)\n",
      "      981    0.001    0.000    0.003    0.000 serializers.py:542(read_int)\n",
      "      977    0.001    0.000    0.017    0.000 serializers.py:421(loads)\n",
      "        4    0.001    0.000    0.001    0.000 {numpy.core.multiarray.zeros}\n",
      "      981    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "     12/4    0.000    0.000    0.499    0.125 rdd.py:2345(pipeline_func)\n",
      "      989    0.000    0.000    0.000    0.000 {len}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:259(dump_stream)\n",
      "        4    0.000    0.000    0.289    0.072 <ipython-input-34-70e5b75fae3f>:22(get_particle_bin_partition_numpy)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "        4    0.000    0.000    0.500    0.125 worker.py:104(process)\n",
      "        4    0.000    0.000    0.209    0.052 rdd.py:1004(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.dumps}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "        8    0.000    0.000    0.000    0.000 rdd.py:861(func)\n",
      "        4    0.000    0.000    0.135    0.034 spark_util.py:4(wrapped)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:414(dumps)\n",
      "        4    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:995(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 spark_util.py:3(spark_cython)\n",
      "        4    0.000    0.000    0.000    0.000 {iter}\n",
      "        4    0.000    0.000    0.000    0.000 {operator.add}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.show_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumpySerializer(pyspark.serializers.PickleSerializer):\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self, dtype): \n",
    "        self.dtype = dtype\n",
    "        super(NumpySerializer, self).__init__()\n",
    "    \n",
    "    def dumps(self, obj):\n",
    "        return obj.tobytes()\n",
    "    def loads(self, obj):\n",
    "        return np.fromstring(obj, dtype=self.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns = NumpySerializer(pdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_arr_rdd = p_np_arr_rdd._reserialize(pyspark.serializers.BatchedSerializer(NumpySerializer(pdt), 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchedSerializer(NumpySerializer(), 1024)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr_rdd._jrdd_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchedSerializer(PickleSerializer(), 1024)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_np_arr_rdd._jrdd_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 ms, sys: 2.2 ms, total: 33.6 ms\n",
      "Wall time: 380 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time new_arr_rdd.mapPartitions(get_particle_bin_partition_numpy).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = new_arr_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Profile of RDD<id=41>\n",
      "============================================================\n",
      "         2008933 function calls (2008925 primitive calls) in 0.530 seconds\n",
      "\n",
      "   Ordered by: internal time, cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1000004    0.332    0.000    0.436    0.000 rdd.py:1004(<genexpr>)\n",
      "        8    0.094    0.012    0.530    0.066 {sum}\n",
      "  1000000    0.077    0.000    0.077    0.000 rdd.py:553(<lambda>)\n",
      "      977    0.015    0.000    0.015    0.000 {cPickle.loads}\n",
      "     1958    0.007    0.000    0.007    0.000 {method 'read' of 'file' objects}\n",
      "      981    0.002    0.000    0.026    0.000 serializers.py:155(_read_with_length)\n",
      "      981    0.001    0.000    0.027    0.000 serializers.py:136(load_stream)\n",
      "      981    0.001    0.000    0.003    0.000 serializers.py:542(read_int)\n",
      "      977    0.001    0.000    0.016    0.000 serializers.py:421(loads)\n",
      "      981    0.000    0.000    0.000    0.000 {_struct.unpack}\n",
      "      985    0.000    0.000    0.000    0.000 {len}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:259(dump_stream)\n",
      "     12/4    0.000    0.000    0.530    0.132 rdd.py:2345(pipeline_func)\n",
      "        4    0.000    0.000    0.530    0.132 worker.py:104(process)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:217(load_stream)\n",
      "        4    0.000    0.000    0.000    0.000 {cPickle.dumps}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:549(write_int)\n",
      "       12    0.000    0.000    0.530    0.044 rdd.py:316(func)\n",
      "        4    0.000    0.000    0.530    0.132 rdd.py:1004(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 rdd.py:861(func)\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:414(dumps)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "        4    0.000    0.000    0.000    0.000 serializers.py:220(_load_stream_without_unbatching)\n",
      "        4    0.000    0.000    0.000    0.000 {_struct.pack}\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:995(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 rdd.py:288(func)\n",
      "        4    0.000    0.000    0.000    0.000 {iter}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "        4    0.000    0.000    0.000    0.000 {operator.add}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.show_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b100000000000000000000000000000000'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(1 << 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b1'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b1100101'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967296"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.binary_repr(1, width=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.binary_repr(1, width=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967297"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(x+y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000000000000000000000000000000100000000000000000000000000000001'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.binary_repr(int(x+y,2), width=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode a 32-bit partition ID (pid) and 32-bit cluster ID (cid) into one 64-bit integer\n",
    "encode_gid = lambda pid, cid: np.int64(int(np.binary_repr(pid,width=32)+np.binary_repr(cid,width=32),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
