{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# how many cores do we have for the driver\n",
    "ncores = int(os.environ.get('LSB_DJOB_NUMPROC', 1)) \n",
    "\n",
    "# here we set the memory we want spark to use for the driver JVM\n",
    "os.environ['SPARK_DRIVER_MEMORY'] = '%dG'%(ncores*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "\n",
    "conf.set('spark.executor.instances', 44)\n",
    "conf.set('spark.executor.cores', 4)\n",
    "\n",
    "sc = SparkContext('yarn-client', conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bytes_per_particle = 4*6 # 4 bytes, 6 components\n",
    "\n",
    "lcp = np.dtype([('x','f4'),('y','f4'), ('z','f4'), ('vx','f4'), ('vy','f4'), ('vz','f4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "filelist = glob('/cluster/home03/sdid/roskarr/work/euclid/output/euclid.*.lcp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for f in filelist: \n",
    "    if os.path.getsize(f) < bytes_per_particle*10:\n",
    "        shutil.move(f,'/cluster/home03/sdid/roskarr/work/euclid/output/smallfiles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_rdd = sc.binaryRecords('file:///cluster/home03/sdid/roskarr/work/euclid/output/euclid.*.lcp.*', bytes_per_particle)\\\n",
    "             .map(lambda x: np.fromstring(x,lcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19073685"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mins = np.ndarray(1, dtype=lcp)\n",
    "maxs = np.ndarray(1, dtype=lcp)\n",
    "for n in lcp.names: \n",
    "    mins[n] = 1e500\n",
    "    maxs[n] = -1e500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mins(p1, p2): \n",
    "    p_min = np.ndarray(1,dtype=lcp)\n",
    "    for n in lcp.names: \n",
    "        if p1[n] < p2[n]: p_min[n] = p1[n]\n",
    "        else            : p_min[n] = p2[n]\n",
    "    return p_min\n",
    "\n",
    "def get_maxs(p1, p2): \n",
    "    p_max = np.ndarray(1,dtype=lcp)\n",
    "    for n in lcp.names: \n",
    "        if p1[n] > p2[n]: p_max[n] = p1[n]\n",
    "        else            : p_max[n] = p2[n]\n",
    "    return p_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_mins = file_rdd.reduce(get_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_maxs = file_rdd.reduce(get_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def get_bin(p, nbins, p_mins, p_maxs): \n",
    "    dx = (p_maxs['x'] - p_mins['x'])/float(nbins)\n",
    "    dy = (p_maxs['y'] - p_mins['y'])/float(nbins)\n",
    "    dz = (p_maxs['z'] - p_mins['z'])/float(nbins)\n",
    "    xbin = floor((p['x'] + 1)/dx)\n",
    "    ybin = floor((p['y'] + 1)/dy)\n",
    "    zbin = floor((p['z'] + 1)/dz)\n",
    "    \n",
    "    return int(xbin + ybin*nbins + zbin*nbins*nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPartitions = sc.defaultParallelism*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_rdd = file_rdd.keyBy(lambda p: get_bin(p, 20, p_mins, p_maxs)).partitionBy(numPartitions, lambda p: p%numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7029"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_rdd.keys().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "box_counts = mapped_rdd.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(box_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = file_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "particles = file_rdd.filter(lambda p: abs(p['z']) < 1e-2)\\\n",
    "                    .map(lambda p: (p['x'][0], p['y'][0])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = [x[0] for x in particles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [x[1] for x in particles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(xs, ys,',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pynbody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pynbody.load('/cluster/home03/sdid/roskarr/work/euclid/output/allsteps.tipsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(s['vx'], s['vz'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pynbody.plot.image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
