{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "def plot_rectangle(rec, ax=None):\n",
    "    if ax is None: \n",
    "        ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    if isinstance(rec, (list, tuple)):\n",
    "        for r in rec: \n",
    "            plot_rectangle(r,ax)\n",
    "    \n",
    "    else:\n",
    "        size = (rec.maxes-rec.mins)\n",
    "        ax.add_patch(patches.Rectangle(rec.mins, size[0], size[1], fill=False, zorder=-1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#diff = np.float32(0.033068776)\n",
    "diff = np.float32(0.03306878)\n",
    "global_min = -31*diff\n",
    "global_max = 31*diff\n",
    "\n",
    "dom_maxs = np.array([global_max]*3, dtype=np.float64)\n",
    "dom_mins = np.array([global_min]*3, dtype=np.float64)\n",
    "tau = 0.2/12600 # 0.2 times mean interparticle separation\n",
    "#buffer_tau = diff*5./150.\n",
    "Ngrid = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sparkhpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = '/home/ics/roskar/spark'\n",
    "os.environ['SPARK_DRIVER_MEMORY'] = '16G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sparkhpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterid=0\n",
    "\n",
    "if clusterid is None: \n",
    "    sj = sparkhpc.sparkjob.sparkjob(ncores=8,\n",
    "                                memory=50000,\n",
    "                                walltime='08:00', \n",
    "                                cores_per_executor=4, \n",
    "                                memory_per_executor=50000)\n",
    "    sj.wait_to_start()\n",
    "else:\n",
    "    sj = sparkhpc.sparkjob.sparkjob(clusterid=clusterid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td>ClusterID</td>\n",
       "                    <th>Job ID</th>\n",
       "                    <th>Number of cores</th>\n",
       "                    <th>Status</th>\n",
       "                    <th>Spark UI</th>\n",
       "                    <th>Spark URL</th>\n",
       "                    </tr><tr><td>0</td>\n",
       "                    <td>1145</td>\n",
       "                    <td>8</td>\n",
       "                    <td>running</td>\n",
       "                    <td><a target=\"_blank\" href=\"http://172.19.1.158:8080\">http://172.19.1.158:8080</a></td>\n",
       "                    <td>spark://x09y02:7077</td>\n",
       "                  </tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sj.show_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = sparkhpc.start_spark(master=sj.master_url, spark_conf='../conf', \n",
    "                          profiling=False, executor_memory='30000M', graphframes_package='graphframes:graphframes:0.3.0-spark2.0-s_2.11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.setCheckpointDir('file:///zbox/data/roskar/work/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark_fof: Number of input files:  8\n",
      "spark_fof: Total number of particles:  594482071\n"
     ]
    }
   ],
   "source": [
    "import spark_fof\n",
    "reload(spark_fof.spark_fof)\n",
    "reload(spark_fof)\n",
    "path = '/zbox/trove/euclid/2Tlc-final/'\n",
    "\n",
    "nMinMembers = 8\n",
    "nBins = 62\n",
    "minblock = 30\n",
    "maxblock = 32\n",
    "fof_analyzer = spark_fof.spark_fof.LCFOFAnalyzer(sc, path, nMinMembers, nBins, tau, dom_mins, dom_maxs, blockids=range(minblock,maxblock), buffer_tau=tau*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "particle_rdd PythonRDD[5] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fof_analyzer.particle_rdd.setName('particle_rdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark_fof: domain group mapping build took 71.411676 seconds\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'create_map_dict' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b17514081daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfof_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ics/roskar/nbody/spark-fof/spark_fof/spark_fof.pyc\u001b[0m in \u001b[0;36mmerged_rdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerged_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merged_rdd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merged_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merged_rdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ics/roskar/nbody/spark-fof/spark_fof/spark_fof.pyc\u001b[0m in \u001b[0;36m_merge_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m                                   \u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnPartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                                   \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                                   .mapPartitions(create_map_dict, preservesPartitioning=True)).cache()\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcreate_map_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'create_map_dict' referenced before assignment"
     ]
    }
   ],
   "source": [
    "fof_analyzer.merged_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fof_analyzer.merged_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark_fof: domain group mapping build took 71.481189 seconds\n"
     ]
    }
   ],
   "source": [
    "mapping = fof_analyzer._get_level_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[225] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(gid): \n",
    "    pid_p = gid >> 32\n",
    "    gid_p = gid ^ (pid_p << 32)\n",
    "    return pid_p, gid_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map_dict(iterator):\n",
    "    group_map_dict = {g:g_p for g,g_p in iterator}\n",
    "    yield group_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partitioned_mapping = (mapping.map(lambda (g,g_p): (decode(g)[0], (g,g_p)))\n",
    "                              .partitionBy(8)\n",
    "                              .map(lambda (k,v): v, preservesPartitioning=True)\n",
    "                              .mapPartitions(create_map_dict, preservesPartitioning=True)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_mapping.setName('mapping').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = partitioned_mapping + fof_analyzer.fof_rdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remap_local_groups(iterator):    \n",
    "    group_mapping_dict = iterator.next()    \n",
    "    for p_arr in iterator:\n",
    "        spark_fof.spark_fof_c.remap_gid_partition_cython(p_arr, group_mapping_dict)\n",
    "        yield p_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.mapPartitions(remap_local_groups).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark_fof <timing>: domain group mapping build took 77.049951 seconds\n",
      "total groups:  3099992\n",
      "spark_fof: Final group map build took 1.884542 seconds\n",
      "CPU times: user 24.1 s, sys: 992 ms, total: 25.1 s\n",
      "Wall time: 14min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[236] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fof_analyzer.finalize_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sparkhpc.sparkjob:\n"
     ]
    }
   ],
   "source": [
    "sj.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
